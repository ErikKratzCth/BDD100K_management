{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "data_main_folder = Path('C:/Users/erikk/Dataset exjobb/BDD100K')\n",
    "img_folder_100 = data_main_folder / \"bdd100k_images/bdd100k/images/100k/train_and_val\"\n",
    "img_folder_10_train = data_main_folder / \"bdd100k_images/bdd100k/images/10k/train\"\n",
    "img_folder_10_val = data_main_folder / \"bdd100k_images/bdd100k/images/10k/val\"\n",
    "\n",
    "labels_folder = data_main_folder / \"bdd100k_labels_release/bdd100k/labels\"\n",
    "labels_train_file = labels_folder / \"bdd100k_labels_images_train.json\"\n",
    "labels_val_file = labels_folder / \"bdd100k_labels_images_val.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which files in 10k folders are also in 100k folders\n",
    "\n",
    "files_100 = os.listdir(img_folder_100_)\n",
    "files_10_train = os.listdir(img_folder_10_train)\n",
    "files_10_val = os.listdir(img_folder_10_val)\n",
    "\n",
    "counter_1 = 0\n",
    "for filename in files_10_train:\n",
    "    if filename in files_100_train:\n",
    "        counter_1 += 1\n",
    "\n",
    "counter_2 = 0\n",
    "for filename in files_10_val:\n",
    "    if filename in files_100_val:\n",
    "        counter_2 += 1\n",
    "\n",
    "counter_3 = 0\n",
    "for filename in files_10_train:\n",
    "    if filename in files_100_val:\n",
    "        counter_3 += 1\n",
    "\n",
    "counter_4 = 0\n",
    "for filename in files_10_val:\n",
    "    if filename in files_100_train:\n",
    "        counter_4 += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976/7000 files in 10k-train are also in 100k-train\n",
      "0/1000 files in 10k-val are also in 100k-val\n",
      "454/7000 files in 10k-train are also in 100k-val\n",
      "0/1000 files in 10k-val are also in 100k-train\n"
     ]
    }
   ],
   "source": [
    "print(\"%d/%d files in 10k-train are also in 100k-train\" %(counter_1,len(files_10_train)))\n",
    "print(\"%d/%d files in 10k-val are also in 100k-val\" %(counter_2,len(files_10_val)))\n",
    "print(\"%d/%d files in 10k-train are also in 100k-val\" %(counter_3,len(files_10_train)))\n",
    "print(\"%d/%d files in 10k-val are also in 100k-train\" %(counter_4,len(files_10_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_data_train loaded\n",
      "json_data_val loaded\n"
     ]
    }
   ],
   "source": [
    "# Check which entries in json-file is in different image folders\n",
    "\n",
    "with open(labels_train_file) as json_data:\n",
    "    json_data_train = json.load(json_data)\n",
    "print(\"json_data_train loaded\")\n",
    "         \n",
    "with open(labels_val_file) as json_data:\n",
    "    json_data_val = json.load(json_data)\n",
    "print(\"json_data_val loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which files are in train labels\n",
    "train_10_counter_1 = 0\n",
    "train_100_counter_1 = 0\n",
    "val_10_counter_1 = 0\n",
    "val_100_counter_1 = 0\n",
    "for entry in json_data_train:\n",
    "    if entry[\"name\"] in files_10_train:\n",
    "        train_10_counter_1 += 1\n",
    "    if entry[\"name\"] in files_100_train:\n",
    "        train_100_counter_1 += 1\n",
    "    if entry[\"name\"] in files_10_val:\n",
    "        val_10_counter_1 += 1\n",
    "    if entry[\"name\"] in files_100_val:\n",
    "        val_100_counter_1 += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2972/7000 files in train_10_images are labeled in json_train\n",
      "69863/70000 files in train_100_images are labeled in json_train\n",
      "0/1000 files in val_10_images are labeled in json_train\n",
      "0/10000 files in val_100_images are labeled in json_train\n"
     ]
    }
   ],
   "source": [
    "print(\"%d/%d files in train_10_images are labeled in json_train\" % (train_10_counter_1,len(files_10_train)))\n",
    "print(\"%d/%d files in train_100_images are labeled in json_train\" % (train_100_counter_1,len(files_100_train)))\n",
    "print(\"%d/%d files in val_10_images are labeled in json_train\" % (val_10_counter_1,len(files_10_val)))\n",
    "print(\"%d/%d files in val_100_images are labeled in json_train\" % (val_100_counter_1,len(files_100_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_counter_2 = 0\n",
    "train_100_counter_2 = 0\n",
    "val_10_counter_2 = 0\n",
    "val_100_counter_2 = 0\n",
    "for entry in json_data_val:\n",
    "    if entry[\"name\"] in files_10_train:\n",
    "        train_10_counter_2 += 1\n",
    "    if entry[\"name\"] in files_100_train:\n",
    "        train_100_counter_2 += 1\n",
    "    if entry[\"name\"] in files_10_val:\n",
    "        val_10_counter_2 += 1\n",
    "    if entry[\"name\"] in files_100_val:\n",
    "        val_100_counter_2 += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454/7000 files in train_10_images are labeled in json_val\n",
      "0/70000 files in train_100_images are labeled in json_val\n",
      "0/1000 files in val_10_images are labeled in json_val\n",
      "10000/10000 files in val_100_images are labeled in json_val\n"
     ]
    }
   ],
   "source": [
    "print(\"%d/%d files in train_10_images are labeled in json_val\" % (train_10_counter_2,len(files_10_train)))\n",
    "print(\"%d/%d files in train_100_images are labeled in json_val\" % (train_100_counter_2,len(files_100_train)))\n",
    "print(\"%d/%d files in val_10_images are labeled in json_val\" % (val_10_counter_2,len(files_10_val)))\n",
    "print(\"%d/%d files in val_100_images are labeled in json_val\" % (val_100_counter_2,len(files_100_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79863"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
